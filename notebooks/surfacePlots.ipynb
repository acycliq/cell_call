{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger()\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,\n",
    "    format=\"%(asctime)s:%(levelname)s:%(message)s\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flat_list(l):\n",
    "\n",
    "    # make sure it is list of lists\n",
    "    my_list = [x if isinstance(x, (list,)) else [x] for x in l]\n",
    "\n",
    "    # return the flattened list\n",
    "    out = [item for sublist in my_list for item in sublist]\n",
    "    return np.array(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_class(df):\n",
    "    '''\n",
    "    Returns a list with the names of all the optimal/best classes\n",
    "    '''\n",
    "    class_name = df['ClassName']\n",
    "    prob = df['Prob']\n",
    "    out = [class_name[n][np.argmax(prob[n])] for n in range(class_name.shape[0])]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregator(df, column_names, norm):\n",
    "    N = df.shape[0]\n",
    "    temp = pd.DataFrame(np.zeros([N, len(column_names)]), columns=column_names)\n",
    "    for i, key in enumerate(df.index):\n",
    "        labels = df.loc[key, 'ClassName']\n",
    "        prob = df.loc[key, 'Prob']\n",
    "        temp.loc[i, labels] = prob\n",
    "\n",
    "    raw_data = temp.copy()\n",
    "    raw_data.insert(0, 'model_class', df['model_class'].values)\n",
    "\n",
    "    if norm == 'median':\n",
    "        out = temp.median(axis=0)\n",
    "    elif norm == 'mean':\n",
    "        out = temp.mean(axis=0)\n",
    "    elif norm == 'mutual_information':\n",
    "# mutual info only needs raw_data. I create variable out just to full the program and keeps going without crashing.\n",
    "# Out here is just a dummy\n",
    "        out = temp.mean(axis=0)\n",
    "    else:\n",
    "        print('NORM should be either \"mean\", \"media\" or \"mutual_information\"')\n",
    "        out = None\n",
    "\n",
    "#     print(out.sum())\n",
    "    return out, raw_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stripper(x, n):\n",
    "    for i in range(n):\n",
    "        if x.rfind('.') > 0:\n",
    "            x = x[:x.rfind('.')]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mk_dir(target):\n",
    "    if not os.path.exists(target):\n",
    "        os.makedirs(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paramGrid(alpha, beta):\n",
    "    grid = np.meshgrid(alpha, beta)\n",
    "    grid = np.array(grid).T.reshape(-1, 2)\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grouper_helper(A, B):\n",
    "    sums = {}\n",
    "\n",
    "    #check if B is number and cast as a list\n",
    "    if isinstance(B, (int, float)):\n",
    "        B = [B]\n",
    "    \n",
    "    for key, value in zip(A,B):\n",
    "        try:\n",
    "            sums[key] += value\n",
    "        except KeyError:\n",
    "            sums[key] = value\n",
    "            \n",
    "    key_list = list(sums.keys())\n",
    "    value_list = list(sums.values())\n",
    "    return key_list, value_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grouper(mydf, fold):\n",
    "    names = []\n",
    "    prob = []\n",
    "    for i in range(mydf.shape[0]):\n",
    "        n = [stripper(x, fold) for x in mydf.ClassName.iloc[i]]\n",
    "        p = mydf['Prob'].iloc[i]\n",
    "        _names, _prob = grouper_helper(n, p)\n",
    "        names.append(_names)\n",
    "        prob.append(_prob)\n",
    "    \n",
    "    mydf['ClassName'] = names\n",
    "    mydf['Prob'] = prob\n",
    "    return mydf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool(df):\n",
    "#     print('Pooling all Non Neurons together.')\n",
    "    non_neuron = ['Astro.1',\n",
    "                 'Astro.2',\n",
    "                 'Astro.3',\n",
    "                 'Astro.4',\n",
    "                 'Astro.5',\n",
    "                 'Choroid',\n",
    "                 'Endo',\n",
    "                 'Eryth.1',\n",
    "                 'Eryth.2',\n",
    "                 'Microglia.1',\n",
    "                 'Microglia.2',\n",
    "                 'Oligo.1',\n",
    "                 'Oligo.2',\n",
    "                 'Oligo.3',\n",
    "                 'Oligo.4',\n",
    "                 'Oligo.5',\n",
    "                 'Vsmc'\n",
    "                 ]\n",
    "\n",
    "    class_names = df['ClassName']\n",
    "    prob = df['Prob']\n",
    "    out_names = []\n",
    "    out_prob = []\n",
    "    for key, name in enumerate(class_names):\n",
    "        name = ['NonNeuron' if x in non_neuron else x for x in name]\n",
    "        temp = pd.DataFrame({'class_name': name, 'prob': prob[key]} )\n",
    "        temp = temp.groupby('class_name').sum()\n",
    "\n",
    "        out_names.append(temp.index.tolist())\n",
    "        out_prob.append(temp['prob'].tolist())\n",
    "\n",
    "    df['ClassName'] = out_names\n",
    "    df['Prob'] = out_prob\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix(model_data, sim_data, config):\n",
    "    \n",
    "    fold = config['fold']\n",
    "    norm = config['norm']\n",
    "    \n",
    "    'get the model class, ie most likely as this is derived from the model'\n",
    "    _model_class = best_class(model_data)\n",
    "\n",
    "    df = sim_data[[\"Cell_Num\", \"ClassName\", \"Prob\"]]\n",
    "    df = df.assign(model_class=_model_class)\n",
    "    \n",
    "    # if you fold, strip the substrings from the names\n",
    "    df = grouper(df, fold)\n",
    "    \n",
    "    # remove the substring from the model class too\n",
    "    mc = [stripper(x, fold) for x in df.model_class]\n",
    "    df.model_class = mc\n",
    "\n",
    "    all_class_names = sorted(set(flat_list(df.ClassName)))\n",
    "\n",
    "    'get all the unique model_class names'\n",
    "    umc = sorted(list(set(df.model_class)))\n",
    "    \n",
    "    n = len(umc)\n",
    "    m = len(all_class_names)\n",
    "    out = pd.DataFrame(np.zeros((m, n)), columns=umc, index=all_class_names)\n",
    "\n",
    "    'loop over the class names (those assigned my the model)'\n",
    "    appended_data = []\n",
    "    for c in umc:\n",
    "        mask = df['model_class'] == c\n",
    "        temp = df[mask]\n",
    "        agg, raw_data = aggregator(temp, all_class_names, norm)\n",
    "\n",
    "        # store DataFrame in list\n",
    "        appended_data.append(raw_data)\n",
    "        key = agg.index\n",
    "        prob = agg.values\n",
    "        out.loc[key, c] = prob\n",
    "#         print('Finished with %s' % c)\n",
    "\n",
    "    # concatenate along the index(axis=0), overwrite raw_data variable\n",
    "    raw_data = pd.concat(appended_data, axis=0)\n",
    "    return out, raw_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analytics(df):\n",
    "    d = []  #keep here the elements of the diagonal\n",
    "    model_classes = df.columns.values\n",
    "    for c in model_classes:\n",
    "        if c in df.index:\n",
    "            # maybe i should append a zero if c not in the index.\n",
    "            # Now I just ignore this.'\n",
    "            d.append(df.loc[c, c])\n",
    "\n",
    "    avg = np.mean(d)\n",
    "    median = np.median(d)\n",
    "    return avg, median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mkPaths(config):\n",
    "    alpha = config['alpha']\n",
    "    beta = config['beta']\n",
    "    PATH = 'https://raw.githubusercontent.com/acycliq/spacetx/master/dashboard/data/img/'\n",
    "    MODEL_DATA =os.path.join(PATH, 'default_98genes/json/iss.json')\n",
    "\n",
    "    subfolder = 'alpha' + str(alpha) + '_' + 'beta' + str(beta)\n",
    "    fName = 'alpha' + str(alpha) + '_' + 'beta' + str(beta) + '_sims_iss.json'\n",
    "    SIM_DATA = PATH + '/grid' + '/' + config['mode'] + '/' + subfolder + '/' + fName\n",
    "    \n",
    "    config['MODEL_DATA'] = MODEL_DATA\n",
    "    config['SIM_DATA'] = SIM_DATA\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mutual_information(data):\n",
    "    prob = data.iloc[:, 1:]\n",
    "    model_class = data.iloc[:, 0]\n",
    "    # first find the locations in each row where the max occurs\n",
    "    mask = np.zeros(prob.shape)\n",
    "\n",
    "    # loop over the model class=\n",
    "    predictedNames = prob.columns\n",
    "    sampleSize = prob.shape[0]\n",
    "    for i, val in enumerate(model_class):\n",
    "        # find the index in the predicted\n",
    "        if val in predictedNames.tolist():\n",
    "            col_id = predictedNames.tolist().index(val)\n",
    "            mask[i, col_id] = 1\n",
    "\n",
    "    marginals = mask.sum(axis=0) / mask.shape[0]\n",
    "    # contribution = prob.values * mask / marginals\n",
    "    contribution = np.divide(prob.values * mask, marginals, out=np.zeros_like(prob.values), where=marginals != 0)\n",
    "    logContribution = np.log2(contribution, where=(contribution != 0))\n",
    "    mutualInformation = np.sum(logContribution) / sampleSize\n",
    "\n",
    "    return mutualInformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def app(config):\n",
    "    MODEL_DATA = config['MODEL_DATA'], \n",
    "    SIM_DATA = config['SIM_DATA']\n",
    "\n",
    "#     print('in app')\n",
    "#     print(config['MODEL_DATA'])\n",
    "#     print(config['SIM_DATA'])\n",
    "    \n",
    "#     logger.info('reading %s' % config['MODEL_DATA'])\n",
    "    model_data = pd.read_json(config['MODEL_DATA'])\n",
    "    \n",
    "#     logger.info('reading %s' % config['SIM_DATA'])\n",
    "    sim_data = pd.read_json(config['SIM_DATA'])\n",
    "    \n",
    "    if config['groupNonNeurons']:\n",
    "        model_data = pool(model_data)\n",
    "        sim_data = pool(sim_data)\n",
    "    \n",
    "    cm, raw_data = confusion_matrix(model_data, sim_data, config)\n",
    "#     avg, median = analytics(cm)\n",
    "    # mi = mutual_information(raw_data)\n",
    "    \n",
    "    if config['norm'] == 'mutual_information':\n",
    "        out = mutual_information(raw_data)\n",
    "    else:\n",
    "        avg, median = analytics(cm)\n",
    "        out = avg\n",
    "            \n",
    "\n",
    "#     logger.info('done \\r')\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 32 out of 32: Doing alpha: 3.00, beta: 1.00 \r"
     ]
    }
   ],
   "source": [
    "alpha = [0.25, 0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 2.0, 2.25, 2.5, 2.75, 3.0]\n",
    "beta = [0.0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]\n",
    "alpha = [0.25, 3.0]\n",
    "beta = [0.0, 1.0]\n",
    "grid = paramGrid(alpha, beta)\n",
    "config = {}\n",
    "modes = ['constrained', 'unconstrained']\n",
    "groupNonNeurons = [True, False]\n",
    "norms = ['mean']\n",
    "folds = [0, 1]\n",
    "\n",
    "maxIter = len(alpha) * len(beta) * len(modes) * len(groupNonNeurons) * len(norms) * len(folds)\n",
    "out = []\n",
    "iter = 0\n",
    "for mode in modes:\n",
    "    for isNNgrouped in groupNonNeurons:\n",
    "        for norm in norms:\n",
    "            for fold in folds:\n",
    "                for p in grid:\n",
    "                    iter = iter + 1\n",
    "\n",
    "                    config['alpha'] = p[0]\n",
    "                    config['beta'] = p[1]\n",
    "\n",
    "                    config['mode'] = mode\n",
    "                    config['groupNonNeurons'] = isNNgrouped\n",
    "                    config['norm'] = norm\n",
    "                    config['fold'] = fold\n",
    "\n",
    "                    # print( \"mode: %s, norm: %s, fold: %d \"  % (mode, norm, fold) )\n",
    "                    print( \"Iteration: %d out of %d: Doing alpha: %.2f, beta: %.2f \"  % (iter, maxIter, p[0], p[1]) + '\\r',end='' )\n",
    "                    config = mkPaths(config)\n",
    "\n",
    "                    # start the app\n",
    "                    res = app(config)\n",
    "\n",
    "                    # mode, norm, fold, xKey, xLabel, yKey, yLabel, val\n",
    "                    temp = [mode, isNNgrouped, norm, fold, p[0], str(p[0]), p[1], str(p[1]), res]\n",
    "                    # append to array\n",
    "                    out.append(temp)\n",
    "                \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "out_df = pd.DataFrame(out)\n",
    "out_df.columns = ['mode', 'groupNonNeurons', 'norm', 'fold', 'xKey', 'xLabel', 'yKey', 'yLabel', 'val']\n",
    "out_df.to_csv('D:\\Dimitris\\Dropbox\\_grid\\cm_summary2.csv', index=False)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
